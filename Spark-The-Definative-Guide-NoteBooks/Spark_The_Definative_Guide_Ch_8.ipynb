{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "97eac874-f520-454f-baee-05178b6ab12d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Joins<br>\n",
    "-> Inner joins (keep rows with keys that exist in the left and right datasets)<br>\n",
    "-> Outer joins (keep rows with keys in either the left or right datasets)<br>\n",
    "-> Left outer joins (keep rows with keys in the left dataset)<br>\n",
    "-> Right outer joins (keep rows with keys in the right dataset)<br>\n",
    "-> Left semi joins (keep the rows in the left, and only the left, dataset where the key appears in the right dataset)<br>\n",
    "-> Left anti joins (keep the rows in the left, and only the left, dataset where they do not appear in the right dataset)<br>\n",
    "-> Natural joins (perform a join by implicitly matching the columns between the two datasets with the same names)<br>\n",
    "-> Cross (or Cartesian) joins (match every row in the left dataset with every row in the right dataset)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7a00431-5a7b-40b1-a7a4-58dd2aeb80d5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "person = spark.createDataFrame([\n",
    "(0, \"Bill Chambers\", 0, [100]),\n",
    "(1, \"Matei Zaharia\", 1, [500, 250, 100]),\n",
    "(2, \"Michael Armbrust\", 1, [250, 100])])\\\n",
    ".toDF(\"id\", \"name\", \"graduate_program\", \"spark_status\")\n",
    "graduateProgram = spark.createDataFrame([\n",
    "(0, \"Masters\", \"School of Information\", \"UC Berkeley\"),\n",
    "(2, \"Masters\", \"EECS\", \"UC Berkeley\"),\n",
    "(1, \"Ph.D.\", \"EECS\", \"UC Berkeley\")])\\\n",
    ".toDF(\"id\", \"degree\", \"department\", \"school\")\n",
    "sparkStatus = spark.createDataFrame([\n",
    "(500, \"Vice President\"),\n",
    "(250, \"PMC Member\"),\n",
    "(100, \"Contributor\")])\\\n",
    ".toDF(\"id\", \"status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "235dfd9d-ada4-44ef-8a47-11a378f97387",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "person.createOrReplaceTempView(\"person\")\n",
    "graduateProgram.createOrReplaceTempView(\"graduateProgram\")\n",
    "sparkStatus.createOrReplaceTempView(\"sparkStatus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19f7f5ff-13df-4e1f-bfc5-d5ace4b27231",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+----------------+---------------+---+-------+--------------------+-----------+\n| id|            name|graduate_program|   spark_status| id| degree|          department|     school|\n+---+----------------+----------------+---------------+---+-------+--------------------+-----------+\n|  0|   Bill Chambers|               0|          [100]|  0|Masters|School of Informa...|UC Berkeley|\n|  1|   Matei Zaharia|               1|[500, 250, 100]|  1|  Ph.D.|                EECS|UC Berkeley|\n|  2|Michael Armbrust|               1|     [250, 100]|  1|  Ph.D.|                EECS|UC Berkeley|\n+---+----------------+----------------+---------------+---+-------+--------------------+-----------+\n\n+---+----------------+----------------+---------------+---+-------+--------------------+-----------+\n| id|            name|graduate_program|   spark_status| id| degree|          department|     school|\n+---+----------------+----------------+---------------+---+-------+--------------------+-----------+\n|  0|   Bill Chambers|               0|          [100]|  0|Masters|School of Informa...|UC Berkeley|\n|  1|   Matei Zaharia|               1|[500, 250, 100]|  1|  Ph.D.|                EECS|UC Berkeley|\n|  2|Michael Armbrust|               1|     [250, 100]|  1|  Ph.D.|                EECS|UC Berkeley|\n+---+----------------+----------------+---------------+---+-------+--------------------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Inner joins are the default join, so we just need to specify our left DataFrame and join the right in the JOIN expression:\n",
    "joinExpression = person[\"graduate_program\"] == graduateProgram['id']\n",
    "person.join(graduateProgram, joinExpression).show()\n",
    "\n",
    "# We can also specify this explicitly by passing in a third parameter, the joinType:\n",
    "joinType='inner'\n",
    "person.join(graduateProgram, joinExpression, joinType).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b23869b-1cf0-46a0-a37f-f4f0295baa58",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------+----------------+---------------+---+-------+--------------------+-----------+\n|  id|            name|graduate_program|   spark_status| id| degree|          department|     school|\n+----+----------------+----------------+---------------+---+-------+--------------------+-----------+\n|   0|   Bill Chambers|               0|          [100]|  0|Masters|School of Informa...|UC Berkeley|\n|   1|   Matei Zaharia|               1|[500, 250, 100]|  1|  Ph.D.|                EECS|UC Berkeley|\n|   2|Michael Armbrust|               1|     [250, 100]|  1|  Ph.D.|                EECS|UC Berkeley|\n|null|            null|            null|           null|  2|Masters|                EECS|UC Berkeley|\n+----+----------------+----------------+---------------+---+-------+--------------------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Outer Join\n",
    "joinType = 'outer'\n",
    "person.join(graduateProgram, joinExpression, joinType).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71d82d07-e16d-4d36-9a3c-ec1d99d7e370",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+----------------+---------------+---+-------+--------------------+-----------+\n| id|            name|graduate_program|   spark_status| id| degree|          department|     school|\n+---+----------------+----------------+---------------+---+-------+--------------------+-----------+\n|  0|   Bill Chambers|               0|          [100]|  0|Masters|School of Informa...|UC Berkeley|\n|  1|   Matei Zaharia|               1|[500, 250, 100]|  1|  Ph.D.|                EECS|UC Berkeley|\n|  2|Michael Armbrust|               1|     [250, 100]|  1|  Ph.D.|                EECS|UC Berkeley|\n+---+----------------+----------------+---------------+---+-------+--------------------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Left Outer Joins\n",
    "joinType = 'left_outer'\n",
    "joinExpression = person[\"graduate_program\"] == graduateProgram['id']\n",
    "person.join(graduateProgram, joinExpression, joinType).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "049c54c9-7638-4f4d-af78-8b40e7a4a05d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------+----------------+---------------+---+-------+--------------------+-----------+\n|  id|            name|graduate_program|   spark_status| id| degree|          department|     school|\n+----+----------------+----------------+---------------+---+-------+--------------------+-----------+\n|   0|   Bill Chambers|               0|          [100]|  0|Masters|School of Informa...|UC Berkeley|\n|null|            null|            null|           null|  2|Masters|                EECS|UC Berkeley|\n|   2|Michael Armbrust|               1|     [250, 100]|  1|  Ph.D.|                EECS|UC Berkeley|\n|   1|   Matei Zaharia|               1|[500, 250, 100]|  1|  Ph.D.|                EECS|UC Berkeley|\n+----+----------------+----------------+---------------+---+-------+--------------------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Right Outer Joins\n",
    "joinType = 'right_outer'\n",
    "joinExpression = person[\"graduate_program\"] == graduateProgram['id']\n",
    "person.join(graduateProgram, joinExpression, joinType).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7af6235-b24c-49d1-afd8-2bbc2318a9f3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------------+-----------+\n| id| degree|          department|     school|\n+---+-------+--------------------+-----------+\n|  0|Masters|School of Informa...|UC Berkeley|\n|  1|  Ph.D.|                EECS|UC Berkeley|\n+---+-------+--------------------+-----------+\n\n+---+-------+--------------------+-----------------+\n| id| degree|          department|           school|\n+---+-------+--------------------+-----------------+\n|  0|Masters|School of Informa...|      UC Berkeley|\n|  1|  Ph.D.|                EECS|      UC Berkeley|\n|  0|Masters|      Duplicated Row|Duplicated School|\n+---+-------+--------------------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Left Semi Joins\n",
    "# Semi joins are a bit of a departure from the other joins. They do not actually include any values from the right DataFrame. They only compare values to see if the value exists in the second DataFrame. If the value does exist, those rows will be kept in the result, even if there are duplicate keys in the left DataFrame. Think of left semi joins as filters on a DataFrame, as opposed to the function of a conventional join.\n",
    "\n",
    "joinType = \"left_semi\"\n",
    "joinExpression = person[\"graduate_program\"] == graduateProgram['id']\n",
    "graduateProgram.join(person, joinExpression, joinType).show()\n",
    "\n",
    "gradProgram2 = graduateProgram.union(spark.createDataFrame([\n",
    "(0, \"Masters\", \"Duplicated Row\", \"Duplicated School\")]))\n",
    "\n",
    "gradProgram2.join(person, joinExpression, joinType).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c543b640-c91e-4658-bbda-893b58e4735e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----------+-----------+\n| id| degree|department|     school|\n+---+-------+----------+-----------+\n|  2|Masters|      EECS|UC Berkeley|\n+---+-------+----------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Left Anti Joins\n",
    "# Left anti joins are the opposite of left semi joins. Like left semi joins, they do not actually include any values from the right DataFrame. They only compare values to see if the value exists in the second DataFrame. However, rather than keeping the values that exist in the second DataFrame, they keep only the values that do not have a corresponding key in the second DataFrame. Think of anti joins as a NOT IN SQL-style filter.\n",
    "\n",
    "joinType = \"left_anti\"\n",
    "joinExpression = person[\"graduate_program\"] == graduateProgram['id']\n",
    "graduateProgram.join(person, joinExpression, joinType).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8ee88069-a028-4033-b3fb-99fa89a3aab6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Natural Joins\n",
    "# Natural joins make implicit guesses at the columns on which you would like to join. It finds matching columns and returns the results. Left, right, and outer natural joins are all supported.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1297be4b-28ef-4c3a-b405-fa5e966b25c0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------------+-----------+---+----------------+----------------+---------------+\n| id| degree|          department|     school| id|            name|graduate_program|   spark_status|\n+---+-------+--------------------+-----------+---+----------------+----------------+---------------+\n|  0|Masters|School of Informa...|UC Berkeley|  0|   Bill Chambers|               0|          [100]|\n|  1|  Ph.D.|                EECS|UC Berkeley|  1|   Matei Zaharia|               1|[500, 250, 100]|\n|  1|  Ph.D.|                EECS|UC Berkeley|  2|Michael Armbrust|               1|     [250, 100]|\n+---+-------+--------------------+-----------+---+----------------+----------------+---------------+\n\n+---+----------------+----------------+---------------+---+-------+--------------------+-----------+\n| id|            name|graduate_program|   spark_status| id| degree|          department|     school|\n+---+----------------+----------------+---------------+---+-------+--------------------+-----------+\n|  0|   Bill Chambers|               0|          [100]|  0|Masters|School of Informa...|UC Berkeley|\n|  0|   Bill Chambers|               0|          [100]|  2|Masters|                EECS|UC Berkeley|\n|  0|   Bill Chambers|               0|          [100]|  1|  Ph.D.|                EECS|UC Berkeley|\n|  1|   Matei Zaharia|               1|[500, 250, 100]|  0|Masters|School of Informa...|UC Berkeley|\n|  1|   Matei Zaharia|               1|[500, 250, 100]|  2|Masters|                EECS|UC Berkeley|\n|  1|   Matei Zaharia|               1|[500, 250, 100]|  1|  Ph.D.|                EECS|UC Berkeley|\n|  2|Michael Armbrust|               1|     [250, 100]|  0|Masters|School of Informa...|UC Berkeley|\n|  2|Michael Armbrust|               1|     [250, 100]|  2|Masters|                EECS|UC Berkeley|\n|  2|Michael Armbrust|               1|     [250, 100]|  1|  Ph.D.|                EECS|UC Berkeley|\n+---+----------------+----------------+---------------+---+-------+--------------------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Cross (Cartesian) Joins\n",
    "\n",
    "# cross-joins or cartesian products. Cross-joins in simplest terms are inner joins that do not specify a predicate. Cross joins will join every single row in the left DataFrame to ever single row in the right DataFrame. This will cause an absolute explosion in the number of rows contained in the resulting DataFrame. If we have 1,000 rows in each DataFrame, the cross join of these will result in 1,000,000 (1,000 x 1,000) rows. For this reason, we must very explicitly state that you want a cross-join by using the cross join keyword\n",
    "\n",
    "joinType = \"cross\"\n",
    "joinExpression = person[\"graduate_program\"] == graduateProgram['id']\n",
    "graduateProgram.join(person, joinExpression, joinType).show()\n",
    "\n",
    "person.crossJoin(graduateProgram).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "370aea14-6b5b-4d10-ba46-7edc21e236f3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<h1>Challanges In Joins</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e862798c-802f-4fe5-a2cf-85d1074bdc26",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+----------------+---------------+---+--------------+\n|personId|            name|graduate_program|   spark_status| id|        status|\n+--------+----------------+----------------+---------------+---+--------------+\n|       0|   Bill Chambers|               0|          [100]|100|   Contributor|\n|       1|   Matei Zaharia|               1|[500, 250, 100]|500|Vice President|\n|       1|   Matei Zaharia|               1|[500, 250, 100]|250|    PMC Member|\n|       1|   Matei Zaharia|               1|[500, 250, 100]|100|   Contributor|\n|       2|Michael Armbrust|               1|     [250, 100]|250|    PMC Member|\n|       2|Michael Armbrust|               1|     [250, 100]|100|   Contributor|\n+--------+----------------+----------------+---------------+---+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Joins on Complex Types\n",
    "# Any expression is a valid join expression, assuming that it returns a Boolean\n",
    "\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "person.withColumnRenamed(\"id\", \"personId\")\\\n",
    ".join(sparkStatus, expr(\"array_contains(spark_status, id)\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e085c18c-b996-4218-9d9f-35fae1fbc8f7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+----------------+---------------+----------------+-------+--------------------+-----------+\n| id|            name|graduate_program|   spark_status|graduate_program| degree|          department|     school|\n+---+----------------+----------------+---------------+----------------+-------+--------------------+-----------+\n|  0|   Bill Chambers|               0|          [100]|               0|Masters|School of Informa...|UC Berkeley|\n|  1|   Matei Zaharia|               1|[500, 250, 100]|               1|  Ph.D.|                EECS|UC Berkeley|\n|  2|Michael Armbrust|               1|     [250, 100]|               1|  Ph.D.|                EECS|UC Berkeley|\n+---+----------------+----------------+---------------+----------------+-------+--------------------+-----------+\n\n+----------------+\n|graduate_program|\n+----------------+\n|               0|\n|               1|\n|               1|\n+----------------+\n\n+----------------+\n|graduate_program|\n+----------------+\n|               0|\n|               1|\n|               1|\n+----------------+\n\n+---+----------------+----------------+---------------+-------+-------+--------------------+-----------+\n| id|            name|graduate_program|   spark_status|grad_id| degree|          department|     school|\n+---+----------------+----------------+---------------+-------+-------+--------------------+-----------+\n|  0|   Bill Chambers|               0|          [100]|      0|Masters|School of Informa...|UC Berkeley|\n|  1|   Matei Zaharia|               1|[500, 250, 100]|      1|  Ph.D.|                EECS|UC Berkeley|\n|  2|Michael Armbrust|               1|     [250, 100]|      1|  Ph.D.|                EECS|UC Berkeley|\n+---+----------------+----------------+---------------+-------+-------+--------------------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Handling Duplicate Column Names\n",
    "\n",
    "# One of the tricky thing is dealing with duplicate column names in results DataFrame\n",
    "# In DF Spark has a unique ID with in sparks SQL Engine Catalyst\n",
    "# This unique ID is purely internal and not something that we can directly reference.\n",
    "# This makes it quite difficult to refer to a specific column when we have a DataFrame with duplicate column names.\n",
    "\n",
    "# This can occur in two distinct situations:\n",
    "# -> The join expression that we specify does not remove one key from one of the input DataFrames and the keys have the same column name\n",
    "# -> Two columns on which you are not performing the join have the same name\n",
    "\n",
    "# Creating Problematic DF\n",
    "gradProgramDupe = graduateProgram.withColumnRenamed(\"id\", \"graduate_program\")\n",
    "joinExpr = gradProgramDupe[\"graduate_program\"] == person[\"graduate_program\"]\n",
    "person.join(gradProgramDupe, joinExpr).show()\n",
    "# person.join(gradProgramDupe, joinExpr).select(\"graduate_program\").show() # Gives Ambiguity Error Due to Same name of two columns\n",
    "\n",
    "# Approaches To Solve Ambigutiy\n",
    "# 1)  Different join expression\n",
    "# When we have two keys that have the same name, probably the easiest fix is to change the join expression from a Boolean expression to a string or sequence. This automatically removes one of the columns for us during the join:\n",
    "person.join(gradProgramDupe,\"graduate_program\").select(\"graduate_program\").show()\n",
    "\n",
    "# 2) Dropping the column after the join\n",
    "# drop the offending column after the join. When doing this, we need to refer to the column via the original source DataFrame. We can do this if the join uses the same key names or if the source DataFrames have columns that simply have the same name:\n",
    "\n",
    "person.join(gradProgramDupe, joinExpr).drop(person[\"graduate_program\"]).select(\"graduate_program\").show()\n",
    "\n",
    "# 3) Renaming a column before the join\n",
    "# we rename one of our columns before the join\n",
    "gradProgram3 = graduateProgram.withColumnRenamed(\"id\", \"grad_id\")\n",
    "joinExpr = person[\"graduate_program\"] == gradProgram3[\"grad_id\"]\n",
    "person.join(gradProgram3, joinExpr).show()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Spark The Definative Guide Ch 8",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
